{
  "ahiq": {
    "name": "Attention-based Hierarchical IQA (AHIQ)",
    "description": "Deep learning model using hierarchical attention for no-reference image quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "arniqa": {
    "name": "Attention-guided Reference-less Neural IQA",
    "description": "Base ARNIQA model for no-reference quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "arniqa-clive": {
    "name": "ARNIQA (CLIVE Dataset)",
    "description": "ARNIQA variant trained on the CLIVE dataset for in-the-wild image quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "arniqa-csiq": {
    "name": "ARNIQA (CSIQ Dataset)",
    "description": "ARNIQA variant trained on the CSIQ dataset for controlled distortion assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "arniqa-flive": {
    "name": "ARNIQA (FLIVE Dataset)",
    "description": "ARNIQA variant optimized for face image quality assessment using FLIVE dataset",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "arniqa-kadid": {
    "name": "ARNIQA (KADID Dataset)",
    "description": "ARNIQA variant trained on the KADID-10k dataset for authentic distortion assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "arniqa-live": {
    "name": "ARNIQA (LIVE Dataset)",
    "description": "ARNIQA variant trained on the LIVE dataset for standard distortion types",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "arniqa-spaq": {
    "name": "ARNIQA (SPAQ Dataset)",
    "description": "ARNIQA variant specialized for smartphone photo quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "arniqa-tid": {
    "name": "ARNIQA (TID Dataset)",
    "description": "ARNIQA variant trained on the TID2013 dataset for comprehensive distortion types",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "brisque": {
    "name": "Blind/Referenceless Image Spatial Quality Evaluator",
    "description": "Classic NR-IQA method using natural scene statistics",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": false,
    "category": "Traditional"
  },
  "brisque_matlab": {
    "name": "BRISQUE (MATLAB Implementation)",
    "description": "MATLAB-compatible implementation of BRISQUE metric",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": false,
    "category": "Traditional"
  },
  "ckdn": {
    "name": "Cross-scale Knowledge Distillation Network",
    "description": "Multi-scale approach using knowledge distillation for quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "clipiqa": {
    "name": "CLIP Image Quality Assessment",
    "description": "Uses CLIP's vision-language model for quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "clipiqa+": {
    "name": "CLIP Image Quality Assessment Plus",
    "description": "Enhanced version of CLIPIQA with improved performance",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "clipiqa+_rn50_512": {
    "name": "CLIPIQA+ (ResNet-50 512)",
    "description": "CLIPIQA+ variant using ResNet-50 backbone with 512 resolution",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "clipiqa+_vitL14_512": {
    "name": "CLIPIQA+ (ViT-L/14 512)",
    "description": "CLIPIQA+ variant using Vision Transformer Large/14 with 512 resolution",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "clipscore": {
    "name": "CLIPScore",
    "description": "Image-text similarity metric based on CLIP embeddings",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "cnniqa": {
    "name": "CNN-based Image Quality Assessment",
    "description": "Convolutional Neural Network approach for blind image quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "cw_ssim": {
    "name": "Complex Wavelet SSIM",
    "description": "Complex wavelet domain extension of SSIM",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Traditional"
  },
  "dbcnn": {
    "name": "Deep Bilinear CNN",
    "description": "Deep bilinear model for blind image quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "dists": {
    "name": "Deep Image Structure and Texture Similarity",
    "description": "Deep learning metric comparing structural and textural features",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "entropy": {
    "name": "Image Entropy",
    "description": "Measures information content in the image",
    "score_range": [0, 8],
    "type": "nr",
    "higher_better": true,
    "category": "Traditional"
  },
  "fid": {
    "name": "Fr√©chet Inception Distance",
    "description": "Measures similarity of generated images to real images",
    "score_range": [0, 9999],
    "type": "fr",
    "higher_better": false,
    "category": "Deep Learning Based"
  },
  "fsim": {
    "name": "Feature Similarity Index",
    "description": "Evaluates image quality based on phase congruency and gradient magnitude",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Traditional"
  },
  "gmsd": {
    "name": "Gradient Magnitude Similarity Deviation",
    "description": "Measures image quality using gradient magnitude similarities",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": false,
    "category": "Traditional"
  },
  "hyperiqa": {
    "name": "Hyper IQA",
    "description": "Hypernetwork-based approach for blind image quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "ilniqe": {
    "name": "Integrated Local NIQE",
    "description": "Enhanced version of NIQE using local quality features",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": false,
    "category": "Traditional"
  },
  "inception_score": {
    "name": "Inception Score",
    "description": "Measures quality and diversity of generated images using Inception network",
    "score_range": [1, 10],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "laion_aes": {
    "name": "LAION Aesthetics Predictor",
    "description": "Aesthetic quality predictor trained on LAION-Aesthetics dataset",
    "score_range": [0, 10],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "liqe": {
    "name": "Learning-based Image Quality Evaluator",
    "description": "Deep learning model for blind image quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "liqe_mix": {
    "name": "LIQE Mixed Dataset",
    "description": "LIQE variant trained on multiple IQA datasets",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "lpips": {
    "name": "Learned Perceptual Image Patch Similarity",
    "description": "Deep perceptual similarity metric using learned features",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": false,
    "category": "Deep Learning Based"
  },
  "lpips+": {
    "name": "LPIPS Plus",
    "description": "Enhanced version of LPIPS with improved performance",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": false,
    "category": "Deep Learning Based"
  },
  "lpips-vgg": {
    "name": "LPIPS (VGG Backend)",
    "description": "LPIPS using VGG network as feature extractor",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": false,
    "category": "Deep Learning Based"
  },
  "lpips-vgg+": {
    "name": "LPIPS VGG Plus",
    "description": "Enhanced VGG-based LPIPS with additional improvements",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": false,
    "category": "Deep Learning Based"
  },
  "mad": {
    "name": "Most Apparent Distortion",
    "description": "Adaptive quality metric based on distortion visibility",
    "score_range": [0, 100],
    "type": "fr",
    "higher_better": false,
    "category": "Traditional"
  },
  "maniqa": {
    "name": "Multi-dimension Attention Network IQA",
    "description": "Base MANIQA model using multi-dimensional attention",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "maniqa-kadid": {
    "name": "MANIQA (KADID Dataset)",
    "description": "MANIQA variant trained on KADID-10k dataset",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "maniqa-pipal": {
    "name": "MANIQA (PIPAL Dataset)",
    "description": "MANIQA variant trained on PIPAL dataset for perceptual IQA",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "ms_ssim": {
    "name": "Multi-Scale Structural Similarity",
    "description": "Multi-scale version of SSIM for better structural similarity assessment",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Traditional"
  },
  "msswd": {
    "name": "Multi-Scale Sliced Wasserstein Distance",
    "description": "Multi-scale approach using Wasserstein distance for quality assessment",
    "score_range": [0, 100],
    "type": "fr",
    "higher_better": false,
    "category": "Traditional"
  },
  "musiq": {
    "name": "Multi-scale Image Quality Transformer",
    "description": "Base MUSIQ model using transformer architecture",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "musiq-ava": {
    "name": "MUSIQ (AVA Dataset)",
    "description": "MUSIQ variant trained on AVA dataset for aesthetic assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "musiq-paq2piq": {
    "name": "MUSIQ (PAQ2PIQ Dataset)",
    "description": "MUSIQ variant trained on PAQ2PIQ dataset",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "musiq-spaq": {
    "name": "MUSIQ (SPAQ Dataset)",
    "description": "MUSIQ variant optimized for smartphone photo quality",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "nima": {
    "name": "Neural Image Assessment",
    "description": "Deep learning model for aesthetic and technical quality assessment",
    "score_range": [1, 10],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "nima-koniq": {
    "name": "NIMA (KonIQ Dataset)",
    "description": "NIMA variant trained on KonIQ-10k dataset for in-the-wild image quality",
    "score_range": [1, 10],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "nima-spaq": {
    "name": "NIMA (SPAQ Dataset)",
    "description": "NIMA variant optimized for smartphone photo quality",
    "score_range": [1, 10],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "nima-vgg16-ava": {
    "name": "NIMA (VGG16-AVA)",
    "description": "NIMA variant using VGG16 backbone trained on AVA dataset",
    "score_range": [1, 10],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "niqe": {
    "name": "Natural Image Quality Evaluator",
    "description": "Opinion-unaware image quality assessment using natural scene statistics",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": false,
    "category": "Traditional"
  },
  "niqe_matlab": {
    "name": "NIQE (MATLAB Implementation)",
    "description": "MATLAB-compatible implementation of NIQE metric",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": false,
    "category": "Traditional"
  },
  "nlpd": {
    "name": "Normalized Laplacian Pyramid Distance",
    "description": "Multi-scale metric based on normalized Laplacian pyramids",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": false,
    "category": "Traditional"
  },
  "nrqm": {
    "name": "No-Reference Quality Metric",
    "description": "General-purpose no-reference quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Traditional"
  },
  "paq2piq": {
    "name": "Patch Quality 2 Perceptual Image Quality",
    "description": "Patch-based approach for perceptual image quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "pi": {
    "name": "Perceptual Index",
    "description": "Combined metric for perceptual quality assessment",
    "score_range": [0, 10],
    "type": "nr",
    "higher_better": true,
    "category": "Traditional"
  },
  "pieapp": {
    "name": "Perceptual Image-Error Assessment through Pairwise Preference",
    "description": "Learning-based metric using pairwise preferences",
    "score_range": [0, 100],
    "type": "fr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "piqe": {
    "name": "Perception based Image Quality Evaluator",
    "description": "Block-based distortion measurement for quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": false,
    "category": "Traditional"
  },
  "psnr": {
    "name": "Peak Signal-to-Noise Ratio",
    "description": "Standard metric measuring pixel-level differences",
    "score_range": [0, 100],
    "type": "fr",
    "higher_better": true,
    "category": "Traditional"
  },
  "psnry": {
    "name": "PSNR (Y Channel)",
    "description": "PSNR calculated on luminance channel only",
    "score_range": [0, 100],
    "type": "fr",
    "higher_better": true,
    "category": "Traditional"
  },
  "qalign": {
    "name": "Quality Alignment",
    "description": "Alignment-based quality assessment metric",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "qalign_4bit": {
    "name": "Quality Alignment (4-bit)",
    "description": "4-bit variant of QAlign metric",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "qalign_8bit": {
    "name": "Quality Alignment (8-bit)",
    "description": "8-bit variant of QAlign metric",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "ssim": {
    "name": "Structural Similarity Index Measure",
    "description": "Classic metric measuring structural similarity between images",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Traditional"
  },
  "ssimc": {
    "name": "SSIM (Color)",
    "description": "SSIM variant that considers color information",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Traditional"
  },
  "stlpips": {
    "name": "Spatial-Temporal LPIPS",
    "description": "Spatial-temporal extension of LPIPS for video quality",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": false,
    "category": "Deep Learning Based"
  },
  "stlpips-vgg": {
    "name": "Spatial-Temporal LPIPS (VGG)",
    "description": "VGG-based variant of ST-LPIPS",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": false,
    "category": "Deep Learning Based"
  },
  "topiq_fr": {
    "name": "Top-down Image Quality Assessment (Full-Reference)",
    "description": "Full-reference variant of TOPIQ framework",
    "score_range": [0, 100],
    "type": "fr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "topiq_fr-pipal": {
    "name": "TOPIQ-FR (PIPAL Dataset)",
    "description": "TOPIQ-FR variant trained on PIPAL dataset",
    "score_range": [0, 100],
    "type": "fr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "topiq_iaa": {
    "name": "TOPIQ Image Aesthetic Assessment",
    "description": "TOPIQ variant for aesthetic quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "topiq_iaa_res50": {
    "name": "TOPIQ-IAA (ResNet-50)",
    "description": "ResNet-50 based variant of TOPIQ-IAA",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "topiq_nr": {
    "name": "TOPIQ No-Reference",
    "description": "No-reference variant of TOPIQ framework",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "topiq_nr-face": {
    "name": "TOPIQ-NR (Face)",
    "description": "TOPIQ-NR specialized for face image quality",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "topiq_nr-flive": {
    "name": "TOPIQ-NR (FLIVE Dataset)",
    "description": "TOPIQ-NR trained on FLIVE dataset",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "topiq_nr-spaq": {
    "name": "TOPIQ-NR (SPAQ Dataset)",
    "description": "TOPIQ-NR optimized for smartphone photos",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "tres": {
    "name": "Transformer-based Image Quality Assessment",
    "description": "Base TRES model using transformer architecture",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "tres-flive": {
    "name": "TRES (FLIVE Dataset)",
    "description": "TRES variant trained on FLIVE dataset",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "unique": {
    "name": "Unified Image Quality Assessment",
    "description": "Unified approach for both FR and NR quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "uranker": {
    "name": "Universal Image Quality Ranker",
    "description": "Learning-to-rank approach for image quality assessment",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "vif": {
    "name": "Visual Information Fidelity",
    "description": "Information theoretic approach to quality assessment",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Traditional"
  },
  "vsi": {
    "name": "Visual Saliency-based Index",
    "description": "Quality assessment incorporating visual saliency information",
    "score_range": [0, 1],
    "type": "fr",
    "higher_better": true,
    "category": "Traditional"
  },
  "wadiqam_fr": {
    "name": "Weighted Average Deep IQA Metric (Full-Reference)",
    "description": "Full-reference variant of WADIQAM",
    "score_range": [0, 100],
    "type": "fr",
    "higher_better": true,
    "category": "Deep Learning Based"
  },
  "wadiqam_nr": {
    "name": "Weighted Average Deep IQA Metric (No-Reference)",
    "description": "No-reference variant of WADIQAM",
    "score_range": [0, 100],
    "type": "nr",
    "higher_better": true,
    "category": "Deep Learning Based"
  }
}
