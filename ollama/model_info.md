# dolphin-llama3 

- Based on Llama 3 architecture
- Created by Eric Hartford
- Available in 8B and 70B parameter sizes
- Focused on instruction following, conversation, and coding
- Combines vision encoder and language model

Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on Llama 3 that has a variety of instruction, conversational, and coding skills. 

ollama run dolphin-llama3

# dolphin-mixtral 

- Based on Mixtral's mixture of experts architecture
- Created by Eric Hartford
- Uncensored version
- Available in 8x7B and 8x22B sizes
- Specialized in coding tasks

Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of experts models that excels at coding tasks. Created by Eric Hartford. 

ollama run dolphin-mixtral

# llava 

- Multimodal model (images + text)
- Combines vision encoder with Vicuna
- Latest version 1.6
- Designed for general-purpose visual understanding
- End-to-end trained

ðŸŒ‹ LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6. 

ollama run llava

# llama3.2-vision 

- Part of Llama 3 family
- Specialized in image reasoning
- Available in 11B and 90B sizes
- Instruction-tuned
- Multimodal capabilities

Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes. 

ollama run llama3.2-vision

# mistral 

- Created by Mistral AI
- 7B parameter size
- Currently at version 0.3
- Base model for fine-tuning
- Open weights

The 7B model released by Mistral AI, updated to version 0.3. 

ollama run mistral

# mixtral 

- Created by Mistral AI
- Mixture of Experts (MoE) architecture
- Available in 8x7B and 8x22B sizes
- Open weights
- High performance capabilities

A set of Mixture of Experts (MoE) model with open weights by Mistral AI in 8x7b and 8x22b parameter sizes.

ollama run mixtral

# gemma2 

- Created by Google
- Three size variants: 2B, 9B, and 27B
- Optimized for efficiency
- High-performing architecture
- Latest in Google's model series

Google Gemma 2 is a high-performing and efficient model available in three sizes: 2B, 9B, and 27B.

ollama run gemma2

# deepseek-coder-v2 

- Specialized for coding tasks
- Mixture-of-Experts architecture
- GPT4-Turbo comparable performance
- Open-source
- Code-specific optimization

An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks. 

ollama run deepseek-coder-v2

